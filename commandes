git clone https://github.com/ggerganov/llama.cpp
cd llama.cpp
make
python convert-hf-to-gguf.py --model deepseek-coder --output deepseek-coder.gguf
ollama create deepseek-coder -f deepseek-coder.gguf
ollama run deepseek-coder "Ã‰cris-moi un script Python qui trie une liste."


(myenv) ut3lfx@udvpaap00000sz0:/data/users/ut3lfx/ollama/llama.cpp 
 # python3.8 convert_hf_to_gguf.py --model ../deepseek-coder --output ../deepseek-coder.gguf
Traceback (most recent call last):
  File "convert_hf_to_gguf.py", line 22, in <module>
    import torch
  File "/data/users/ut3lfx/ollama/myenv/lib/python3.8/site-packages/torch/__init__.py", line 18, in <module>
    import ctypes
  File "/data/users/ut3lfx/localpython/lib/python3.8/ctypes/__init__.py", line 7, in <module>
    from _ctypes import Union, Structure, Array
ModuleNotFoundError: No module named '_ctypes'


find /usr/lib -name "_ctypes.so"
find ~/ -name "_ctypes.so"
export PYTHONPATH=/chemin/vers/_ctypes.so:$PYTHONPATH
python -c "import _ctypes; print('ctypes fonctionne')"





python -c "import sys; print(sys.path)"
python -c "help('modules') | grep ctypes"

ls /usr/bin/python*
/usr/bin/python3.8 -c "import _ctypes; print('ctypes fonctionne')"


Envoyer ce qu'il y'a dans blobs et dans manifest



git clone https://huggingface.co/deepseek-ai/deepseek-coder
pip install torch numpy sentencepiece
python convert-hf-to-gguf.py \
    --model ../deepseek-coder \
    --output ../deepseek-coder.gguf \
    --architecture deepseek-coder

python convert-hf-to-gguf.py --model ../deepseek-coder --output ../deepseek-coder.gguf --architecture auto


pip install huggingface_hub
from huggingface_hub import snapshot_download

snapshot_download(repo_id="deepseek-ai/deepseek-coder-6.7B", local_dir="deepseek-coder")

root@ollama-5c7f9d64c5-n9fdl:~/.ollama/models/blobs# ollama create deepseek-r1:1.5b --file sha256-aabd4debf0c8f08881923f2c25fc0fdeed24435271c2b3e92c4af36704040dbc

Error: (line 1): command must be one of "from", "license", "template", "system", "adapter", "parameter", or "message"



ollama create deepseek-r1:1.5b --file Modelfile   

modelfile : FROM deepseek-r1:1.5b
